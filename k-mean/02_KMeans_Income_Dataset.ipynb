{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dde12f",
   "metadata": {},
   "source": [
    "### **K-Means Clustering with Income Dataset**\n",
    "\n",
    "This notebook demonstrates the application of the K-Means clustering algorithm on a dataset containing information about individuals' age and income. We will preprocess the data, perform clustering, visualize the results, and analyze the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123bc43c",
   "metadata": {},
   "source": [
    "#### **1. Import Libraries**\n",
    "\n",
    "Import the necessary libraries for data manipulation, clustering, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ff393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9fb30e",
   "metadata": {},
   "source": [
    "#### **2. Load the Dataset**\n",
    "\n",
    "Load the `income.csv` dataset, which contains information about individuals' `Name`, `Age`, and `Income`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fb7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('income.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458e16f",
   "metadata": {},
   "source": [
    "#### **3. Visualize the Data**\n",
    "\n",
    "Before applying clustering, we visualize the data to understand its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.Age, df['Income'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Income')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176825f3",
   "metadata": {},
   "source": [
    "#### **4. Apply K-Means Clustering**\n",
    "\n",
    "Apply K-Means clustering with three clusters (`k=3`) and add the cluster assignments to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac582b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3)\n",
    "y_predicted = km.fit_predict(df[['Age', 'Income']])\n",
    "df['cluster'] = y_predicted\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95001561",
   "metadata": {},
   "source": [
    "#### **5. Analyze Cluster Centers**\n",
    "\n",
    "The cluster centers represent the average values of `Age` and `Income` for each cluster. These centers can help interpret the clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ff43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32048a40",
   "metadata": {},
   "source": [
    "#### **6. Visualize Clusters**\n",
    "\n",
    "Visualize the clusters along with their centroids to understand the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dc174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.cluster == 0]\n",
    "df2 = df[df.cluster == 1]\n",
    "df3 = df[df.cluster == 2]\n",
    "\n",
    "plt.scatter(df1.Age, df1['Income'], color='green')\n",
    "plt.scatter(df2.Age, df2['Income'], color='red')\n",
    "plt.scatter(df3.Age, df3['Income'], color='black')\n",
    "plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], color='purple', marker='*', label='centroid')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Income')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528ae90",
   "metadata": {},
   "source": [
    "#### **7. Normalize the Data**\n",
    "The KMeans clustering algorithm is sensitive to the scale of the data. If one feature (e.g., Income) has a much larger range or variance than another feature (e.g., Age), then the clustering will be dominated by the feature with the larger range. This is because the algorithm is based on calculating distances between data points.\n",
    "\n",
    "\n",
    "We normalize the `Age` and `Income` features to scale them between 0 and 1, which can improve clustering performance when features have different ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e077e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(df[['Income']])\n",
    "df['Income'] = scaler.transform(df[['Income']])\n",
    "\n",
    "scaler.fit(df[['Age']])\n",
    "df['Age'] = scaler.transform(df[['Age']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e232f0",
   "metadata": {},
   "source": [
    "#### **8. Revisualize Normalized Data**\n",
    "\n",
    "After normalization, visualize the data again to confirm the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28add0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.Age, df['Income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d903196",
   "metadata": {},
   "source": [
    "#### **9. Reapply K-Means Clustering**\n",
    "\n",
    "Reapply K-Means clustering on the normalized data to get updated cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3)\n",
    "y_predicted = km.fit_predict(df[['Age', 'Income']])\n",
    "df['cluster'] = y_predicted\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f414b",
   "metadata": {},
   "source": [
    "#### **10. Revisualize Clusters with Normalized Data**\n",
    "\n",
    "Visualize the clusters again after normalization to see the updated centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b434626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.cluster == 0]\n",
    "df2 = df[df.cluster == 1]\n",
    "df3 = df[df.cluster == 2]\n",
    "\n",
    "plt.scatter(df1.Age, df1['Income'], color='green')\n",
    "plt.scatter(df2.Age, df2['Income'], color='red')\n",
    "plt.scatter(df3.Age, df3['Income'], color='black')\n",
    "plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], color='purple', marker='*', label='centroid')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01a041",
   "metadata": {},
   "source": [
    "#### **11. Elbow Method**\n",
    "\n",
    "The Elbow Method helps determine the optimal number of clusters by plotting the sum of squared errors (SSE) for different values of `k`. The point where the SSE begins to diminish significantly is the optimal `k`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "k_rng = range(1, 10)\n",
    "for k in k_rng:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(df[['Age', 'Income']])\n",
    "    sse.append(km.inertia_)\n",
    "\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Sum of squared error')\n",
    "plt.plot(k_rng, sse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
